{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold, train_test_split, cross_val_score, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import silhouette_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, roc_auc_score, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "#visualizing results\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import yellowbrick as yb\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(X, y, model_instance, feature_names, fi_name):\n",
    "    #takes in features (X) and classess (y), model, column names for features in X, and name of attribute for feature importance\n",
    "    #returns dictionary of feature names and coef/feature importance values\n",
    "    \n",
    "    feature_importance_dic = {}\n",
    "    \n",
    "    model_instance.fit(X, y)\n",
    "    \n",
    "    if fi_name == 'coef':\n",
    "        coef = model_instance.coef_[0]\n",
    "        feature_importance_dic = dict(zip(feature_names, coef))\n",
    "    if fi_name == 'feature_importance':\n",
    "        coef = model_instance.feature_importances_\n",
    "        feature_importance_dic = dict(zip(feature_names, coef))\n",
    "    if fi_name == 'none':\n",
    "        coef = np.zeros(len(feature_names))\n",
    "        feature_importance_dic = dict(zip(feature_names, coef))\n",
    "    \n",
    "    return feature_importance_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_pipeline(X, y, cv_instance, model_instance, feature_names, fi_name):\n",
    "    \n",
    "    #scale data\n",
    "    data_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    #generate cross-val sets\n",
    "    cv = list(cv_instance.split(data_scaled, y))\n",
    "    \n",
    "    #predict class and predict probability \n",
    "    y_pred = cross_val_predict(model_instance, data_scaled, y, cv=cv, method='predict')\n",
    "    y_pred_prob = cross_val_predict(model_instance, data_scaled, y, cv=cv, method='predict_proba')\n",
    "    \n",
    "    #generate confusion matrix\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    print('Confusion matrix:', conf_mat)\n",
    "    \n",
    "    #generate ROC_AUC\n",
    "    ROC_AUC = metrics.roc_auc_score(y, y_pred_prob[:,1])\n",
    "    print(\"ROC_AUC: \", ROC_AUC)\n",
    "    \n",
    "    # generate additional metrics\n",
    "    recall = metrics.recall_score(y,y_pred)\n",
    "    precision = metrics.precision_score(y,y_pred)\n",
    "    accuracy = metrics.accuracy_score(y,y_pred)\n",
    "    F1 = metrics.f1_score(y,y_pred)\n",
    "    print(\"Sensitivity/Recall (TPR): \",recall)\n",
    "    print(\"Precision (PPV): \", precision)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"F1:\", F1)\n",
    "    \n",
    "    #determine feature importance\n",
    "    feature_dic = feature_importance(data_scaled, y, model_instance, feature_names, fi_name)\n",
    "    \n",
    "    #create dic\n",
    "    data_dic = {}\n",
    "    data_dic['y_pred'] = y_pred\n",
    "    data_dic['y_pred_prob'] = y_pred_prob\n",
    "    data_dic['conf_mat'] = conf_mat\n",
    "    data_dic['ROC_AUC'] = ROC_AUC\n",
    "    data_dic['recall'] = recall\n",
    "    data_dic['precision'] = precision\n",
    "    data_dic['accuracy'] = accuracy\n",
    "    data_dic['F1'] = F1\n",
    "    \n",
    "    data_dic = {**data_dic, **feature_dic}\n",
    "    \n",
    "    return data_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a predictions column for subesquent viz of TN, TP, FN, FP\n",
    "def conf_mat_column(dataframe, model_name):\n",
    "    preds = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "\n",
    "        if (row['Group'] == 0) & (row[model_name] == 0):\n",
    "            pred = 'TN'\n",
    "        if (row['Group'] == 0) & (row[model_name] == 1):\n",
    "            pred = 'FP'\n",
    "        if (row['Group'] == 1) & (row[model_name] == 1):\n",
    "            pred = 'TP'\n",
    "        if (row['Group'] == 1) & (row[model_name] == 0):\n",
    "            pred = 'FN'\n",
    "          \n",
    "        preds.append(pred)\n",
    "      \n",
    "    dataframe[str('pred_' + model_name)] = preds\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn code\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Escalation/Phillips/Combined.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['actnp', 'Inactnp', 'actTO', 'avgIII', 'inactTO', 'days2crit', 'lat2fir']\n",
      "actnp\n",
      "Inactnp\n",
      "actTO\n",
      "avgIII\n",
      "inactTO\n",
      "days2crit\n",
      "lat2fir\n",
      "(80, 81)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal</th>\n",
       "      <th>Group</th>\n",
       "      <th>actnp_plus1</th>\n",
       "      <th>actnp_plus2</th>\n",
       "      <th>actnp_plus3</th>\n",
       "      <th>actnp_plus4</th>\n",
       "      <th>actnp_plus5</th>\n",
       "      <th>actnp_minus_5</th>\n",
       "      <th>actnp_minus_4</th>\n",
       "      <th>actnp_minus_3</th>\n",
       "      <th>actnp_minus_2</th>\n",
       "      <th>actnp_minus_1</th>\n",
       "      <th>actnp_full_ave</th>\n",
       "      <th>actnp_last_ave</th>\n",
       "      <th>actnp_first_ave</th>\n",
       "      <th>Inactnp_plus1</th>\n",
       "      <th>Inactnp_plus2</th>\n",
       "      <th>Inactnp_plus3</th>\n",
       "      <th>Inactnp_plus4</th>\n",
       "      <th>Inactnp_plus5</th>\n",
       "      <th>Inactnp_minus_5</th>\n",
       "      <th>Inactnp_minus_4</th>\n",
       "      <th>Inactnp_minus_3</th>\n",
       "      <th>Inactnp_minus_2</th>\n",
       "      <th>Inactnp_minus_1</th>\n",
       "      <th>Inactnp_full_ave</th>\n",
       "      <th>Inactnp_last_ave</th>\n",
       "      <th>Inactnp_first_ave</th>\n",
       "      <th>actTO_plus1</th>\n",
       "      <th>actTO_plus2</th>\n",
       "      <th>actTO_plus3</th>\n",
       "      <th>actTO_plus4</th>\n",
       "      <th>actTO_plus5</th>\n",
       "      <th>actTO_minus_5</th>\n",
       "      <th>actTO_minus_4</th>\n",
       "      <th>actTO_minus_3</th>\n",
       "      <th>actTO_minus_2</th>\n",
       "      <th>actTO_minus_1</th>\n",
       "      <th>actTO_full_ave</th>\n",
       "      <th>actTO_last_ave</th>\n",
       "      <th>actTO_first_ave</th>\n",
       "      <th>avgIII_plus1</th>\n",
       "      <th>avgIII_plus2</th>\n",
       "      <th>avgIII_plus3</th>\n",
       "      <th>avgIII_plus4</th>\n",
       "      <th>avgIII_plus5</th>\n",
       "      <th>avgIII_minus_5</th>\n",
       "      <th>avgIII_minus_4</th>\n",
       "      <th>avgIII_minus_3</th>\n",
       "      <th>avgIII_minus_2</th>\n",
       "      <th>avgIII_minus_1</th>\n",
       "      <th>avgIII_full_ave</th>\n",
       "      <th>avgIII_last_ave</th>\n",
       "      <th>avgIII_first_ave</th>\n",
       "      <th>inactTO_plus1</th>\n",
       "      <th>inactTO_plus2</th>\n",
       "      <th>inactTO_plus3</th>\n",
       "      <th>inactTO_plus4</th>\n",
       "      <th>inactTO_plus5</th>\n",
       "      <th>inactTO_minus_5</th>\n",
       "      <th>inactTO_minus_4</th>\n",
       "      <th>inactTO_minus_3</th>\n",
       "      <th>inactTO_minus_2</th>\n",
       "      <th>inactTO_minus_1</th>\n",
       "      <th>inactTO_full_ave</th>\n",
       "      <th>inactTO_last_ave</th>\n",
       "      <th>inactTO_first_ave</th>\n",
       "      <th>days2crit</th>\n",
       "      <th>lat2fir_plus1</th>\n",
       "      <th>lat2fir_plus2</th>\n",
       "      <th>lat2fir_plus3</th>\n",
       "      <th>lat2fir_plus4</th>\n",
       "      <th>lat2fir_plus5</th>\n",
       "      <th>lat2fir_minus_5</th>\n",
       "      <th>lat2fir_minus_4</th>\n",
       "      <th>lat2fir_minus_3</th>\n",
       "      <th>lat2fir_minus_2</th>\n",
       "      <th>lat2fir_minus_1</th>\n",
       "      <th>lat2fir_full_ave</th>\n",
       "      <th>lat2fir_last_ave</th>\n",
       "      <th>lat2fir_first_ave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2223</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.272727</td>\n",
       "      <td>18.8</td>\n",
       "      <td>16.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>433.69429</td>\n",
       "      <td>215.425</td>\n",
       "      <td>241.95429</td>\n",
       "      <td>156.70045</td>\n",
       "      <td>198.64611</td>\n",
       "      <td>130.57462</td>\n",
       "      <td>182.12895</td>\n",
       "      <td>170.5415</td>\n",
       "      <td>202.24412</td>\n",
       "      <td>189.33389</td>\n",
       "      <td>205.107868</td>\n",
       "      <td>174.964616</td>\n",
       "      <td>249.284028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>68.11</td>\n",
       "      <td>73.63</td>\n",
       "      <td>85.62</td>\n",
       "      <td>42.51</td>\n",
       "      <td>10.25</td>\n",
       "      <td>31.86</td>\n",
       "      <td>77.88</td>\n",
       "      <td>26.81</td>\n",
       "      <td>2640.67</td>\n",
       "      <td>75.58</td>\n",
       "      <td>295.264545</td>\n",
       "      <td>570.56</td>\n",
       "      <td>56.024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Animal  Group  actnp_plus1  actnp_plus2  actnp_plus3  actnp_plus4  actnp_plus5  actnp_minus_5  actnp_minus_4  actnp_minus_3  actnp_minus_2  actnp_minus_1  actnp_full_ave  actnp_last_ave  actnp_first_ave  Inactnp_plus1  Inactnp_plus2  Inactnp_plus3  Inactnp_plus4  Inactnp_plus5  Inactnp_minus_5  Inactnp_minus_4  Inactnp_minus_3  Inactnp_minus_2  Inactnp_minus_1  Inactnp_full_ave  Inactnp_last_ave  Inactnp_first_ave  actTO_plus1  actTO_plus2  actTO_plus3  actTO_plus4  actTO_plus5  actTO_minus_5  actTO_minus_4  actTO_minus_3  actTO_minus_2  actTO_minus_1  actTO_full_ave  actTO_last_ave  actTO_first_ave  avgIII_plus1  avgIII_plus2  avgIII_plus3  avgIII_plus4  avgIII_plus5  avgIII_minus_5  avgIII_minus_4  avgIII_minus_3  avgIII_minus_2  avgIII_minus_1  avgIII_full_ave  avgIII_last_ave  avgIII_first_ave  inactTO_plus1  inactTO_plus2  inactTO_plus3  inactTO_plus4  inactTO_plus5  inactTO_minus_5  inactTO_minus_4  inactTO_minus_3  inactTO_minus_2  inactTO_minus_1  inactTO_full_ave  \\\n",
       "0    2223      1          8.0         17.0         15.0         23.0         19.0           27.0           20.0           21.0            7.0           19.0       18.272727            18.8             16.4            8.0           10.0            5.0            4.0            1.0              1.0              1.0              1.0              1.0              1.0          3.333333               1.0                5.6          2.0          9.0          1.0          3.0          3.0            4.0            3.0            1.0            3.0            3.0        4.583333             2.8              3.6     433.69429       215.425     241.95429     156.70045     198.64611       130.57462       182.12895        170.5415       202.24412       189.33389       205.107868       174.964616        249.284028            0.0            0.0            2.0            1.0            1.0              0.0              0.0              0.0              0.0              0.0          0.363636   \n",
       "\n",
       "   inactTO_last_ave  inactTO_first_ave  days2crit  lat2fir_plus1  lat2fir_plus2  lat2fir_plus3  lat2fir_plus4  lat2fir_plus5  lat2fir_minus_5  lat2fir_minus_4  lat2fir_minus_3  lat2fir_minus_2  lat2fir_minus_1  lat2fir_full_ave  lat2fir_last_ave  lat2fir_first_ave  \n",
       "0               0.0                0.8          4          68.11          73.63          85.62          42.51          10.25            31.86            77.88            26.81          2640.67            75.58        295.264545            570.56             56.024  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#excel file containing multiple sheets with rat cocaine self administration data (day 1 of training through reaching criteria)\n",
    "#original file has multiple sheets (for different feature types) - most sheets have multiple days (columns) of training data\n",
    "#use first five days and last five days of training as feature data (6 different self administration parameters to use)\n",
    "#singe data point of days to criterion - use also\n",
    "\n",
    "whole_file = pd.ExcelFile(path)\n",
    "\n",
    "print(whole_file.sheet_names)\n",
    "\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "for sheet_name in whole_file.sheet_names:\n",
    "    print(sheet_name)\n",
    "\n",
    "    if sheet_name != 'days2crit':\n",
    "        \n",
    "        sheet_data = pd.DataFrame(data = pd.read_excel(whole_file, sheetname=sheet_name, header=None))\n",
    "        sheet_data.rename({0: 'Group', 1: 'Animal'}, inplace=True, axis=1)\n",
    "        sheet_data = sheet_data[['Group', 'Animal', 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n",
    "           16, 17, 18, 19, 20, 21, 22, 23]]\n",
    "\n",
    "        for index, row in sheet_data.iterrows():\n",
    "            sheet_data.loc[sheet_data.index[index], str(sheet_name + '_minus_5')] = row.dropna()[-5]\n",
    "            sheet_data.loc[sheet_data.index[index], str(sheet_name + '_minus_4')] = row.dropna()[-4]\n",
    "            sheet_data.loc[sheet_data.index[index], str(sheet_name + '_minus_3')] = row.dropna()[-3]\n",
    "            sheet_data.loc[sheet_data.index[index], str(sheet_name + '_minus_2')] = row.dropna()[-2]\n",
    "            sheet_data.loc[sheet_data.index[index], str(sheet_name + '_minus_1')] = row.dropna()[-1]\n",
    "            \n",
    "            sheet_data.loc[sheet_data.index[index], str(sheet_name + '_plus1')] = row.dropna()[2]\n",
    "            sheet_data.loc[sheet_data.index[index], str(sheet_name + '_plus2')] = row.dropna()[3]\n",
    "            sheet_data.loc[sheet_data.index[index], str(sheet_name + '_plus3')] = row.dropna()[4]\n",
    "            sheet_data.loc[sheet_data.index[index], str(sheet_name + '_plus4')] = row.dropna()[5]\n",
    "            sheet_data.loc[sheet_data.index[index], str(sheet_name + '_plus5')] = row.dropna()[6]\n",
    "            \n",
    "            sheet_data.loc[sheet_data.index[index], str(sheet_name + '_full_ave')] = row.dropna()[2:].mean()\n",
    "            \n",
    "        sheet_data = sheet_data[['Animal', 'Group', \n",
    "                                 str(sheet_name + '_plus1'), \\\n",
    "                                str(sheet_name + '_plus2'), \\\n",
    "                                str(sheet_name + '_plus3'), \\\n",
    "                                str(sheet_name + '_plus4'), \\\n",
    "                                str(sheet_name + '_plus5'), \\\n",
    "                                 str(sheet_name + '_minus_5'), \\\n",
    "                                str(sheet_name + '_minus_4'), \\\n",
    "                                str(sheet_name + '_minus_3'), \\\n",
    "                                str(sheet_name + '_minus_2'), \\\n",
    "                                str(sheet_name + '_minus_1'),\n",
    "                                str(sheet_name + '_full_ave')]]\n",
    "        \n",
    "        sheet_data[str(sheet_name + '_last_ave')] = sheet_data.loc[:, str(sheet_name + '_minus_5'): str(sheet_name + '_minus_1')].mean(axis=1)\n",
    "        sheet_data[str(sheet_name + '_first_ave')] = sheet_data.loc[:, str(sheet_name + '_plus1'): str(sheet_name + '_plus5')].mean(axis=1)\n",
    "    \n",
    "    if sheet_name == 'days2crit':\n",
    "        sheet_data = pd.DataFrame(data = pd.read_excel(whole_file, sheetname=sheet_name, header=None))\n",
    "        sheet_data.rename({0: 'Group', 1: 'Animal'}, inplace=True, axis=1)\n",
    "        sheet_data = sheet_data[['Group', 'Animal', 2]]\n",
    "    \n",
    "    if combined_data.shape[0] == 0:\n",
    "        combined_data = sheet_data\n",
    "    else:\n",
    "        combined_data = pd.merge(combined_data, sheet_data, how='inner', on=['Animal', 'Group'], suffixes=(sheet_name, sheet_name))\n",
    "\n",
    "combined_data.reset_index(drop=True, inplace=True)\n",
    "print(combined_data.shape)\n",
    "combined_data.rename({2:'days2crit'}, axis=1, inplace=True)\n",
    "combined_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    54\n",
       "1    26\n",
       "Name: Group, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['Group'] = combined_data['Group'].replace({2:0})\n",
    "combined_data['Group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual feature selection and model training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = combined_data[['Group',\n",
    "                      'actnp_full_ave',\n",
    "                     'Inactnp_full_ave',\n",
    "               'actTO_full_ave', \n",
    "                'avgIII_full_ave',\n",
    "                     'inactTO_full_ave',\n",
    "                     'lat2fir_full_ave',\n",
    "                      'actnp_first_ave',\n",
    "                     'Inactnp_first_ave',\n",
    "               'actTO_first_ave', \n",
    "                'avgIII_first_ave',\n",
    "                     'inactTO_first_ave',\n",
    "                     'lat2fir_first_ave',\n",
    "                    'actnp_last_ave',\n",
    "                     'Inactnp_last_ave',\n",
    "               'actTO_last_ave', \n",
    "                'avgIII_last_ave',\n",
    "                     'inactTO_last_ave',\n",
    "                     'lat2fir_last_ave',\n",
    "                     'days2crit']].corr()\n",
    "corr['Group'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_full = ['actnp_plus1', 'actnp_plus2', 'actnp_plus3',\n",
    "       'actnp_plus4', 'actnp_plus5', 'actnp_minus_5', 'actnp_minus_4',\n",
    "       'actnp_minus_3', 'actnp_minus_2', 'actnp_minus_1', \n",
    "       'actTO_plus1', 'actTO_plus2', 'actTO_plus3', 'actTO_plus4',\n",
    "       'actTO_plus5', 'actTO_minus_5', 'actTO_minus_4', 'actTO_minus_3',\n",
    "       'actTO_minus_2', 'actTO_minus_1', 'avgIII_plus1',\n",
    "       'avgIII_plus2', 'avgIII_plus3', 'avgIII_plus4', 'avgIII_plus5',\n",
    "       'avgIII_minus_5', 'avgIII_minus_4', 'avgIII_minus_3',\n",
    "       'avgIII_minus_2', 'avgIII_minus_1', 'inactTO_plus1',\n",
    "       'inactTO_plus2', 'inactTO_plus3', 'inactTO_plus4', 'inactTO_plus5',\n",
    "       'inactTO_minus_5', 'inactTO_minus_4', 'inactTO_minus_3',\n",
    "       'inactTO_minus_2', 'inactTO_minus_1', \n",
    "       'days2crit']\n",
    "\n",
    "features_ave_full = ['actnp_full_ave',\n",
    "               'actTO_full_ave', \n",
    "                     'inactTO_full_ave',\n",
    "                'avgIII_full_ave',\n",
    "                     'days2crit']\n",
    "\n",
    "features_ave_firstlast = ['actnp_first_ave',\n",
    "               'actTO_first_ave', \n",
    "                'avgIII_first_ave',\n",
    "                          'lat2fir_first_ave',\n",
    "                    'actnp_last_ave',\n",
    "               'actTO_last_ave', \n",
    "                'avgIII_last_ave',\n",
    "                     'inactTO_last_ave',\n",
    "          'days2crit']\n",
    "\n",
    "features_ave_last = ['actnp_last_ave',\n",
    "               'actTO_last_ave', \n",
    "                'avgIII_last_ave',\n",
    "                     'inactTO_last_ave',\n",
    "                    'days2crit']\n",
    "\n",
    "all_ave = ['actnp_first_ave',\n",
    " 'Inactnp_first_ave',\n",
    "               'actTO_first_ave', \n",
    "                'avgIII_first_ave',\n",
    "                     'inactTO_first_ave',\n",
    "                     'lat2fir_first_ave',\n",
    "                    'actnp_last_ave',\n",
    "                     'Inactnp_last_ave',\n",
    "               'actTO_last_ave', \n",
    "                'avgIII_last_ave',\n",
    "                     'inactTO_last_ave',\n",
    "                     'lat2fir_last_ave',\n",
    "        'actnp_full_ave',\n",
    "                     'Inactnp_full_ave',\n",
    "               'actTO_full_ave', \n",
    "                'avgIII_full_ave',\n",
    "                     'inactTO_full_ave',\n",
    "                     'lat2fir_full_ave',\n",
    "                     'days2crit']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in all_ave:\n",
    "    print(param)\n",
    "    sns.barplot(x=combined_data[\"Group\"], y=combined_data[param])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "train, test = train_test_split(combined_data, test_size = .3, random_state=1, stratify = combined_data['Group'])\n",
    "\n",
    "Y_train_class = train['Group']\n",
    "Y_test_class = test['Group']\n",
    "\n",
    "X_train_full = train[features_full]\n",
    "X_train_ave_full = train[features_ave_full]\n",
    "X_train_ave_last = train[features_ave_last]\n",
    "X_train_ave_firstlast = train[features_ave_firstlast]\n",
    "\n",
    "X_test_full = test[features_full]\n",
    "X_test_ave_full = test[features_ave_full]\n",
    "X_test_ave_last = test[features_ave_last]\n",
    "X_test_ave_firstlast = test[features_ave_firstlast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data algo\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#k fold algo\n",
    "strat_k_fold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "#classifier algos\n",
    "dm_cv = DummyClassifier(strategy='stratified', random_state=39)\n",
    "lr_cv = LogisticRegression(random_state=39, class_weight='balanced')\n",
    "rf_cv = RandomForestClassifier(random_state=39, class_weight='balanced')\n",
    "svm_cv = SVC(kernel='linear', probability=True, class_weight='balanced') \n",
    "knn_cv = KNeighborsClassifier()\n",
    "gb_cv = GradientBoostingClassifier(random_state=39)\n",
    "ab_cv = AdaBoostClassifier(random_state=39)\n",
    "\n",
    "#dic with classifier and feature importance attribute name\n",
    "models_dic = {'dm_cv': (dm_cv, 'none'), \n",
    "              'lr_cv': (lr_cv, 'coef'), \n",
    "              'rf_cv': (rf_cv, 'feature_importance'), \n",
    "              'svm_cv':(svm_cv, 'coef'), \n",
    "              'knn_cv': (knn_cv, 'none'), \n",
    "              'gb_cv': (gb_cv, 'feature_importance'), \n",
    "              'ab_cv': (ab_cv, 'feature_importance')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_set = 'full'\n",
    "feature_names = features_full\n",
    "\n",
    "data_full_features = {}\n",
    "\n",
    "for name, model in models_dic.items():\n",
    "    print(f'{name} model with {feature_set} features:')\n",
    "    data_full_features[name + '_' + feature_set] = classification_pipeline(X_train_full, Y_train_class, strat_k_fold, model[0], feature_names, model[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_set = 'ave_full'\n",
    "feature_names = features_ave_full\n",
    "\n",
    "data_ave_full_features = {}\n",
    "\n",
    "for name, model in models_dic.items():\n",
    "    print(f'{name} model with {feature_set} features:')\n",
    "    data_ave_full_features[name + '_' + feature_set] = classification_pipeline(X_train_ave_full, Y_train_class, strat_k_fold, model[0], feature_names, model[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_set = 'firstlast'\n",
    "feature_names = features_ave_firstlast\n",
    "\n",
    "data_firstlast_features = {}\n",
    "\n",
    "for name, model in models_dic.items():\n",
    "    print(f'{name} model with {feature_set} features:')\n",
    "    data_firstlast_features[name + '_' + feature_set] = classification_pipeline(X_train_ave_firstlast, Y_train_class, strat_k_fold, model[0], feature_names, model[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_set = 'ave_last'\n",
    "feature_names = features_ave_last\n",
    "\n",
    "data_ave_last_features = {}\n",
    "\n",
    "for name, model in models_dic.items():\n",
    "    print(f'{name} model with {feature_set} features:')\n",
    "    data_ave_last_features[name + '_' + feature_set] = classification_pipeline(X_train_ave_last, Y_train_class, strat_k_fold, model[0], feature_names, model[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put dics in pandas df \n",
    "final_dic = {**data_full_features, **data_ave_full_features, **data_firstlast_features, **data_ave_last_features}\n",
    "data_pandas = pd.DataFrame.from_dict(data = final_dic, orient='index')\n",
    "data_pandas.sort_values('F1', ascending=False)\n",
    "#data_pandas.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_dm, tpr_dm, thresholds_dm = metrics.roc_curve(Y_train_class, data_ave_full_features['dm_cv_ave_full']['y_pred_prob'][:,1])\n",
    "fpr_lr, tpr_lr, thresholds_lr = metrics.roc_curve(Y_train_class, data_ave_full_features['lr_cv_ave_full']['y_pred_prob'][:,1])\n",
    "fpr_rf, tpr_rf, thresholds_rf = metrics.roc_curve(Y_train_class, data_ave_full_features['rf_cv_ave_full']['y_pred_prob'][:,1])\n",
    "fpr_svm, tpr_svm, thresholds_svm = metrics.roc_curve(Y_train_class, data_ave_full_features['svm_cv_ave_full']['y_pred_prob'][:,1])\n",
    "fpr_knn, tpr_knn, thresholds_knn = metrics.roc_curve(Y_train_class, data_ave_full_features['knn_cv_ave_full']['y_pred_prob'][:,1])\n",
    "fpr_ab, tpr_ab, thresholds_ab = metrics.roc_curve(Y_train_class, data_ave_full_features['ab_cv_ave_full']['y_pred_prob'][:,1])\n",
    "\n",
    "\n",
    "# plot model ROC curves\n",
    "plt.plot(fpr_dm, tpr_dm, label=\"dm\")\n",
    "plt.plot(fpr_lr, tpr_lr, label=\"lr\")\n",
    "plt.plot(fpr_rf, tpr_rf, label=\"rf\")\n",
    "plt.plot(fpr_svm, tpr_svm, label=\"svm\")\n",
    "plt.plot(fpr_knn, tpr_knn, label=\"knn\")\n",
    "plt.plot(fpr_ab, tpr_ab, label=\"ab\")\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1.05])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('Classifer ROCs', fontsize=20)\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', fontsize = 15)\n",
    "plt.ylabel('True Positive Rate (Sensitivity)', fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate precision-recall curve\n",
    "precision_dm, recall_dm, thresholds_pr_dm = metrics.precision_recall_curve(Y_train_class, data_ave_full_features['dm_cv_ave_full']['y_pred_prob'][:,1])\n",
    "precision_lr, recall_lr, thresholds_pr_lr = metrics.precision_recall_curve(Y_train_class, data_ave_full_features['lr_cv_ave_full']['y_pred_prob'][:,1])\n",
    "precision_rf, recall_rf, thresholds_pr_rf = metrics.precision_recall_curve(Y_train_class, data_ave_full_features['rf_cv_ave_full']['y_pred_prob'][:,1])\n",
    "precision_svm, recall_svm, thresholds_pr_svm = metrics.precision_recall_curve(Y_train_class, data_ave_full_features['svm_cv_ave_full']['y_pred_prob'][:,1])\n",
    "precision_knn, recall_knn, thresholds_pr_knn = metrics.precision_recall_curve(Y_train_class, data_ave_full_features['knn_cv_ave_full']['y_pred_prob'][:,1])\n",
    "precision_ab, recall_ab, thresholds_pr_ab = metrics.precision_recall_curve(Y_train_class, data_ave_full_features['ab_cv_ave_full']['y_pred_prob'][:,1])\n",
    "\n",
    "plt.plot(recall_dm, precision_dm, label='dm')\n",
    "plt.plot(recall_lr, precision_lr, label='lr')\n",
    "plt.plot(recall_rf, precision_rf, label='rf')\n",
    "plt.plot(recall_svm, precision_svm, label='svm')\n",
    "plt.plot(recall_knn, precision_knn, label='knn')\n",
    "plt.plot(recall_ab, precision_ab, label='ab')\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1.05])\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('Classifer Precision vs Recall', fontsize=20)\n",
    "plt.xlabel('Recall (Sensitivity)', fontsize = 15)\n",
    "plt.ylabel('Precision', fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data for grid search\n",
    "train_scaled = scaler.fit_transform(X_train_ave_full)\n",
    "\n",
    "#grid search with cv for ada and ave last features\n",
    "param_grid = {'n_estimators':(25, 50, 100, 250), 'learning_rate':(0.1, 1.0), 'algorithm':('SAMME', 'SAMME.R')}\n",
    "scoring = ['accuracy', 'f1', 'precision', 'recall', 'roc_auc']\n",
    "\n",
    "ab_base = AdaBoostClassifier(random_state=39)\n",
    "\n",
    "ab_gs = GridSearchCV(ab_base, param_grid, cv=3, scoring = scoring, refit='f1')\n",
    "ab_gs.fit(train_scaled, Y_train_class)\n",
    "\n",
    "print(\"f1:\"+str(np.average(cross_val_score(ab_gs, train_scaled, Y_train_class, scoring='f1'))))\n",
    "print(\"ROC_AUC:\"+str(np.average(cross_val_score(ab_gs, train_scaled, Y_train_class, scoring='roc_auc'))))\n",
    "\n",
    "print(ab_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:0.6825396825396824\n",
      "ROC_AUC:0.7496438746438746\n",
      "Accuracy:0.7855750487329435\n",
      "Adaboost train AUC: 0.9821428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        38\n",
      "           1       0.95      1.00      0.97        18\n",
      "\n",
      "   micro avg       0.98      0.98      0.98        56\n",
      "   macro avg       0.97      0.99      0.98        56\n",
      "weighted avg       0.98      0.98      0.98        56\n",
      "\n",
      "[[37  1]\n",
      " [ 0 18]]\n"
     ]
    }
   ],
   "source": [
    "#use best params\n",
    "\n",
    "#scale data for grid search\n",
    "train_scaled = scaler.fit_transform(X_train_ave_full)\n",
    "\n",
    "ada_best = AdaBoostClassifier(algorithm='SAMME', learning_rate=1.0, n_estimators=50, random_state=39)\n",
    "\n",
    "print(\"f1:\"+str(np.average(cross_val_score(ada_best, train_scaled, Y_train_class, scoring='f1'))))\n",
    "print(\"ROC_AUC:\"+str(np.average(cross_val_score(ada_best, train_scaled, Y_train_class, scoring='roc_auc'))))\n",
    "print(\"Accuracy:\"+str(np.average(cross_val_score(ada_best, train_scaled, Y_train_class, scoring='accuracy'))))\n",
    "\n",
    "ada_best.fit(train_scaled, Y_train_class)\n",
    "\n",
    "train_pred_ada = ada_best.predict(train_scaled)\n",
    "train_pred_prob_ada = ada_best.predict_proba(train_scaled)\n",
    "\n",
    "print('Adaboost train AUC: {}'.format(ada_best.score(train_scaled, Y_train_class)))\n",
    "print(classification_report(Y_train_class, train_pred_ada))\n",
    "print(confusion_matrix(Y_train_class, train_pred_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[37  1]\n",
      " [ 0 18]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(Y_train_class, train_pred_ada, classes=Y_train_class.unique(), normalize=False,\n",
    "                      title='Confusion matrix: Ada Boost Training Set')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost test AUC: 0.7916666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85        16\n",
      "           1       0.71      0.62      0.67         8\n",
      "\n",
      "   micro avg       0.79      0.79      0.79        24\n",
      "   macro avg       0.77      0.75      0.76        24\n",
      "weighted avg       0.79      0.79      0.79        24\n",
      "\n",
      "[[14  2]\n",
      " [ 3  5]]\n"
     ]
    }
   ],
   "source": [
    "#run on test data\n",
    "#scale data\n",
    "test_scaled = scaler.fit_transform(X_test_ave_full)\n",
    "\n",
    "print('Adaboost test AUC: {}'.format(ada_best.score(test_scaled, Y_test_class)))\n",
    "test_pred_ada = ada_best.predict(test_scaled)\n",
    "test_pred_prob_ada = ada_best.predict_proba(test_scaled)\n",
    "print(classification_report(Y_test_class, test_pred_ada))\n",
    "print(confusion_matrix(Y_test_class, test_pred_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[14  2]\n",
      " [ 3  5]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(Y_test_class, test_pred_ada, classes=Y_test_class.unique(), normalize=False,\n",
    "                      title='Confusion matrix: Ada Boost Test Set')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data for grid search\n",
    "train_scaled = scaler.fit_transform(X_train_ave_full)\n",
    "\n",
    "#grid search with cv for svm and ave last features\n",
    "param_grid = {'C':(0.001, 0.01, 0.1, 1, 10), 'decision_function_shape':('ovo','ovr')}\n",
    "scoring = ['accuracy', 'f1', 'precision', 'recall', 'roc_auc']\n",
    "\n",
    "svm_base = SVC(kernel='linear', class_weight='balanced', random_state=39)\n",
    "\n",
    "svm_gs = GridSearchCV(svm_base, param_grid, cv=3, scoring = scoring, refit='f1')\n",
    "svm_gs.fit(train_scaled, Y_train_class)\n",
    "\n",
    "print(\"f1:\"+str(np.average(cross_val_score(svm_gs, train_scaled, Y_train_class, scoring='f1'))))\n",
    "print(\"ROC_AUC:\"+str(np.average(cross_val_score(svm_gs, train_scaled, Y_train_class, scoring='roc_auc'))))\n",
    "\n",
    "print(svm_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use best params\n",
    "\n",
    "svm_best = SVC(probability=True, kernel='linear', class_weight='balanced', C=10, decision_function_shape='ovo', random_state=39)\n",
    "    \n",
    "print(\"f1:\"+str(np.average(cross_val_score(svm_best, train_scaled, Y_train_class, scoring='f1'))))\n",
    "print(\"ROC_AUC:\"+str(np.average(cross_val_score(svm_best, train_scaled, Y_train_class, scoring='roc_auc'))))\n",
    "print(\"Accuracy:\"+str(np.average(cross_val_score(svm_best, train_scaled, Y_train_class, scoring='accuracy'))))\n",
    "\n",
    "svm_best.fit(train_scaled, Y_train_class)\n",
    "print(svm_best.score(train_scaled, Y_train_class))\n",
    "\n",
    "train_pred_svm = svm_best.predict(train_scaled)\n",
    "train_pred_prob_svm = svm_best.predict_proba(train_scaled)\n",
    "print(classification_report(Y_train_class, train_pred_svm))\n",
    "print(confusion_matrix(Y_train_class, train_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run on test data\n",
    "#scale data\n",
    "test_scaled = scaler.fit_transform(X_test_ave_full)\n",
    "\n",
    "print('SVM test AUC: {}'.format(svm_best.score(test_scaled, Y_test_class)))\n",
    "test_pred_svm = svm_best.predict(test_scaled)\n",
    "test_pred_prob_svm = svm_best.predict_proba(test_scaled)\n",
    "print(classification_report(Y_test_class, test_pred_svm))\n",
    "print(confusion_matrix(Y_test_class, test_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize false positives and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new columns for each model's pred prob and the best model's pred class\n",
    "train['class_svm'] = train_pred_svm\n",
    "train['pred_prob_svm'] = train_pred_prob_svm[:,1]\n",
    "\n",
    "#create a predictions column for subesquent viz of TN, TP, FN, FP\n",
    "model_name = 'class_svm'\n",
    "train = conf_mat_column(train, model_name)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['actnp_full_ave',\n",
    "               'actTO_full_ave', \n",
    "                     'inactTO_full_ave',\n",
    "                'avgIII_full_ave',\n",
    "                     'days2crit',\n",
    "          'pred_prob_svm',\n",
    "       'pred_class_svm']\n",
    "\n",
    "i=1\n",
    "plt.figure(figsize=(30,20))\n",
    "for param in params:\n",
    "    print(param)\n",
    "    plt.subplot(4, 4, i)\n",
    "    sns.barplot(x=train[\"Group\"], y=train[param], hue=train[\"pred_class_svm\"])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new columns for each model's pred prob and the best model's pred class\n",
    "test['class_svm'] = test_pred_svm\n",
    "test['pred_prob_svm'] = test_pred_prob_svm[:,1]\n",
    "\n",
    "#create a predictions column for subesquent viz of TN, TP, FN, FP\n",
    "model_name = 'class_svm'\n",
    "test = conf_mat_column(test, model_name)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['actnp_full_ave',\n",
    "               'actTO_full_ave', \n",
    "                     'inactTO_full_ave',\n",
    "                'avgIII_full_ave',\n",
    "                     'days2crit',\n",
    "          'pred_prob_svm',\n",
    "       'pred_class_svm']\n",
    "\n",
    "i=1\n",
    "plt.figure(figsize=(30,20))\n",
    "for param in params:\n",
    "    print(param)\n",
    "    plt.subplot(4, 4, i)\n",
    "    sns.barplot(x=test[\"Group\"], y=test[param], hue=test[\"pred_class_svm\"])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = test[['Animal', 'Group', 'class_svm', 'pred_prob_svm', 'pred_class_svm', 'actnp_full_ave',\n",
    "               'actTO_full_ave', \n",
    "                     'inactTO_full_ave',\n",
    "                'avgIII_full_ave',\n",
    "                     'days2crit']].sort_values('pred_class_svm')\n",
    "\n",
    "test_params.groupby('pred_class_svm').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "train, test = train_test_split(combined_data, test_size = .3, random_state=1, stratify = combined_data['Group'])\n",
    "\n",
    "Y_train_class = train['Group']\n",
    "Y_test_class = test['Group']\n",
    "\n",
    "X_train_full = train[features_full]\n",
    "X_train_ave_full = train[features_ave_full]\n",
    "X_train_ave_last = train[features_ave_last]\n",
    "X_train_ave_firstlast = train[features_ave_firstlast]\n",
    "\n",
    "X_test_full = test[features_full]\n",
    "X_test_ave_full = test[features_ave_full]\n",
    "X_test_ave_last = test[features_ave_last]\n",
    "X_test_ave_firstlast = test[features_ave_firstlast]\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_ave_full)\n",
    "X_test_scaled = scaler.fit_transform(X_test_ave_full)\n",
    " \n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('lr', lr_cv), ('rf', rf_cv), ('svm', svm_cv), ('knn', knn_cv), ('gb', gb_cv), ('ab', ab_cv)], \n",
    "                         voting='hard', weights=[5,1,1,1,1,5])\n",
    "eclf1 = eclf1.fit(X_train_scaled, Y_train_class)\n",
    "print('Train AUC with hard voting: ', eclf1.score(X_train_scaled, Y_train_class))\n",
    "print('Test AUC with hard voting: ', eclf1.score(X_test_scaled, Y_test_class))\n",
    "test_pred_hard = eclf1.predict(X_test_scaled)\n",
    "print(classification_report(Y_test_class, test_pred_hard))\n",
    "print(confusion_matrix(Y_test_class, test_pred_hard))\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[\n",
    "        ('lr', lr_cv), ('rf', rf_cv), ('svm', svm_cv), ('knn', knn_cv), ('gb', gb_cv), ('ab', ab_cv)], \n",
    "                         voting='soft', weights=[5,1,1,1,1,5])\n",
    "eclf2 = eclf2.fit(X_train_scaled, Y_train_class)\n",
    "print('Train AUC with soft voting: ', eclf2.score(X_train_scaled, Y_train_class))\n",
    "print('Test AUC with soft voting: ', eclf2.score(X_test_scaled, Y_test_class))\n",
    "test_pred_hard = eclf2.predict(X_test_scaled)\n",
    "test_pred_prob_hard = eclf2.predict_proba(X_test_scaled)\n",
    "print(classification_report(Y_test_class, test_pred_hard))\n",
    "print(confusion_matrix(Y_test_class, test_pred_hard))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive feature elimination for feature selection and model training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_train_ave_full\n",
    "\n",
    "#scale data\n",
    "X = scaler.fit_transform(data)\n",
    "y = Y_train_class\n",
    "\n",
    "svm_best = SVC(probability=True, kernel='linear', class_weight='balanced', decision_function_shape='ovo', random_state=39)\n",
    "selector = RFECV(svm_best, step=1, cv=3)\n",
    "selector = selector.fit(X, y)\n",
    "feature_rankings = list(zip(data.columns.values, selector.ranking_))\n",
    "\n",
    "print(\"Optimal number of features : %d\" % selector.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(selector.grid_scores_) + 1), selector.grid_scores_)\n",
    "plt.show()\n",
    "\n",
    "feature_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['actnp_first_ave', 'Inactnp_first_ave', 'actTO_first_ave',\n",
    "       'avgIII_first_ave', 'inactTO_first_ave', 'lat2fir_first_ave',\n",
    "       'days2crit', 'actnp_last_ave', 'Inactnp_last_ave',\n",
    "       'actTO_last_ave', 'avgIII_last_ave', 'inactTO_last_ave',\n",
    "       'lat2fir_last_ave']\n",
    "\n",
    "cv5_features = ['actnp_first_ave', 'Inactnp_first_ave', 'actTO_first_ave', 'lat2fir_first_ave', 'actnp_last_ave', \n",
    "                 'Inactnp_last_ave', 'avgIII_last_ave', 'inactTO_last_ave']\n",
    "\n",
    "cv3_features = ['lat2fir_first_ave', 'actnp_last_ave', 'Inactnp_last_ave']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cv3_features\n",
    "\n",
    "#split data\n",
    "train, test = train_test_split(combined_data, test_size = .3, random_state=1, stratify = combined_data['Group'])\n",
    "\n",
    "Y_train_class = train['Group']\n",
    "Y_test_class = test['Group']\n",
    "\n",
    "X_train_rfe = train[data]\n",
    "\n",
    "X_test_rfe = test[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "data_scaled = scaler.fit_transform(X_train_rfe)\n",
    "\n",
    "#grid search with cv for svm and ave last features\n",
    "param_grid = {'C':(0.001, 0.01, 0.1, 1, 10), 'decision_function_shape':('ovo','ovr')}\n",
    "scoring = ['accuracy', 'f1', 'precision', 'recall', 'roc_auc']\n",
    "\n",
    "svm_base = SVC(kernel='linear', class_weight='balanced', random_state=39)\n",
    "\n",
    "svm_gs = GridSearchCV(svm_base, param_grid, cv=3, scoring = scoring, refit='f1')\n",
    "svm_gs.fit(data_scaled, Y_train_class)\n",
    "\n",
    "print(\"f1:\"+str(np.average(cross_val_score(svm_gs, data_scaled, Y_train_class, scoring='f1'))))\n",
    "print(\"ROC_AUC:\"+str(np.average(cross_val_score(svm_gs, data_scaled, Y_train_class, scoring='roc_auc'))))\n",
    "\n",
    "print(svm_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_best = SVC(probability=True, kernel='linear', class_weight='balanced', C=10, decision_function_shape='ovo', random_state=39)\n",
    "    \n",
    "print(\"f1:\"+str(np.average(cross_val_score(svm_best, data_scaled, Y_train_class, scoring='f1'))))\n",
    "print(\"ROC_AUC:\"+str(np.average(cross_val_score(svm_best, data_scaled, Y_train_class, scoring='roc_auc'))))\n",
    "print(\"Accuracy:\"+str(np.average(cross_val_score(svm_best, data_scaled, Y_train_class, scoring='accuracy'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_best.fit(data_scaled, Y_train_class)\n",
    "print(svm_best.score(data_scaled, Y_train_class))\n",
    "\n",
    "#scale data\n",
    "data_scaled_test = scaler.fit_transform(X_test_rfe)\n",
    "\n",
    "print('SVM test AUC: {}'.format(svm_best.score(data_scaled_test, Y_test_class)))\n",
    "test_pred_svm = svm_best.predict(data_scaled_test)\n",
    "test_pred_prob_svm = svm_best.predict_proba(data_scaled_test)\n",
    "print(classification_report(Y_test_class, test_pred_svm))\n",
    "print(confusion_matrix(Y_test_class, test_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cluster = combined_data[['actnp_last_ave', \n",
    "                'Inactnp_last_ave', \n",
    "               'actTO_last_ave', \n",
    "                'avgIII_last_ave']]\n",
    "\n",
    "# center and scale the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "features_clust_scaled = scaler.fit_transform(features_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(2,10)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    km_ss = KMeans(n_clusters=k, random_state=1)\n",
    "    km_ss.fit(features_clust_scaled)\n",
    "    scores.append(silhouette_score(features_clust_scaled, km_ss.labels_))\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km2 = KMeans(n_clusters=2,random_state=1234)\n",
    "km2.fit(features_clust_scaled)\n",
    "combined_data['kmeans_2_scaled'] = [ \"cluster_\" + str(label) for label in km2.labels_ ]\n",
    "combined_data.groupby('kmeans_2_scaled').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.groupby('Group')['kmeans_2_scaled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=50, random_state=1234)\n",
    "tsne_features = tsne.fit_transform(features_clust_scaled)\n",
    "\n",
    "print(tsne_features.shape)\n",
    "tsne_df = pd.DataFrame(data = tsne_features, columns = ['tsne_0', 'tsne_1'], index = combined_data.index)\n",
    "combined_data = pd.concat([combined_data, tsne_df], axis = 1)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(x_vars='tsne_0', y_vars='tsne_1', data=combined_data, hue='Group')\n",
    "plt.show()\n",
    "sns.pairplot(x_vars='tsne_0', y_vars='tsne_1', data=combined_data, hue='kmeans_2_scaled')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
